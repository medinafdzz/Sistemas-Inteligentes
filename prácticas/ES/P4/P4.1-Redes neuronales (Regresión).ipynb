{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Práctica 4.1: Redes neuronales (Regresión)**\n",
    "\n",
    "<hr>\n",
    "\n",
    "## **1. Introducción**\n",
    "En prácticas anteriores aprendimos a resolver problemas de clasificación y regresión utilizando métodos o modelos de aprendizaje automático clásico. En esta práctica 4 veremos cómo resolver ese tipo de problemas utilizando **Redes Neuronales**, los métodos más utilizados en la actualidad. \n",
    "\n",
    "Estas redes son la base del *Deep Learning* y tienen la capacidad de ser muy versátiles al estar compuestas por múltiples neuronas organizadas en capas. A estas neuronas también se les denomina *perceptrones*, es por eso que a las redes neuronales también se les conoce como **Perceptrones Multicapa**.\n",
    "\n",
    "Al igual que sucedía con el resto de modelos, dentro de `scikit-learn` tenemos un par de clases que nos facilitan el uso de estas redes:\n",
    "\n",
    "* **MLPRegressor:** Perceptrón multicapa pensado para resolver problemas de regresión.\n",
    "* **MLPClassifier:** Perceptrón multicapa pensado para resolver problemas de clasificación.\n",
    "\n",
    "En este tipo de modelos no vamos a utilizar estas clases predefinidas, ya que nos interesa ver cómo es su arquitectura y funcionamiento interno. Por este motivo utilizaremos una nueva librería, [`tensorflow`](https://www.tensorflow.org/), la cual es una de las más utilizadas en Python para llevar a cabo tareas de deep learning junto con [`pytorch`](https://pytorch.org/).\n",
    "\n",
    "### **Objetivos**\n",
    "En esta práctica aprenderás a:\n",
    "* Crear y entrenar Redes Neuronales.\n",
    "* Optimizar sus hiperparámetros.\n",
    "* Añadir funciones de activación no lineales.\n",
    "\n",
    "Comenzaremos instalando la librería en nuestro environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una de las ventajas de las redes neuronales es que se pueden entrenar en CPU o GPU. \n",
    "\n",
    "Más adelante veremos como entrenar una de estas redes en las GPUs de los ordenadores de prácticas buscando acelerar el proceso de entrenamiento. En tu ordenador personal, es probable solo puedas ejecutar en CPU.\n",
    "\n",
    "A continuación cargamos una vez más nuestros datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "seed = 2533\n",
    "data = pd.read_pickle(\"https://raw.githubusercontent.com/AIC-Uniovi/Sistemas-Inteligentes/refs/heads/main/datasets/f1_23_monaco.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## **2. Problemas de regresión**\n",
    "\n",
    "Vamos a intentar resolver el mismo problema de la práctica anterior, es decir: \n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Crear un modelo que, dado el tiempo en el primer sector <code>Sector1Time</code> sea capaz de predecir el tiempo total de la vuelta <code>LapTime</code>.</b>\n",
    "</div>\n",
    "\n",
    "Lo primero que haremos será crear los datasets necesarios para entrenar un modelo.\n",
    "\n",
    "### **2.1. Preprocesado de datos**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Ejercicio:</b> Separa las X e Y del dataframe <code>data_sector2lap</code> , divide en entrenamiento y test (80/20) fijando la semilla y finalmente <b>estandariza</b> las X.\n",
    "    <hr>\n",
    "    Cuando la X solo tiene una columna, es necesario utilizar dobles corchetes (<code>data[[\"nombrecolumna\"]]</code> y no <code>data[\"nombrecolumna\"]</code>) para que funcione correctamente el <code>StandardScaler()</code>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data_sector2lap = data[[\"LapTime\", \"Sector1Time\"]].copy()\n",
    "data_sector2lap[\"LapTime\"] = data_sector2lap[\"LapTime\"].dt.total_seconds()\n",
    "data_sector2lap[\"Sector1Time\"] = data_sector2lap[\"Sector1Time\"].dt.total_seconds()\n",
    "\n",
    "# Tu código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.2. Aprendizaje automático**\n",
    "\n",
    "Con los datos listos, entrenaremos y evaluaremos de nuevo los modelos de aprendizaje automático ya conocidos para poder compararlos con nuestro nuevo sistema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Ejercicio:</b> Entrena y evalúa los modelos restantes (<i>K-Nearest Neighbors</i>, <i>Árboles de decisión</i> y <i>SVR</i>) utilizando la siguiente función.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "def evaluate_model(Y_test, preds_test, model_name):\n",
    "    metrics = {\n",
    "        \"Métrica\": [\"MAE\", \"MSE\", \"R²\"],\n",
    "        \"TEST\": [mean_absolute_error(Y_test, preds_test), \n",
    "                 mean_squared_error(Y_test, preds_test), \n",
    "                 r2_score(Y_test, preds_test)]\n",
    "    }\n",
    "    df = pd.DataFrame(metrics)\n",
    "    print(f\"Resultados para {model_name}:\")\n",
    "    print(df.to_string(index=False))\n",
    "    print()\n",
    "\n",
    "# Baseline media\n",
    "baseline_media = DummyRegressor(strategy=\"mean\")\n",
    "baseline_media.fit(X_train, Y_train)\n",
    "preds_test = baseline_media.predict(X_test)\n",
    "evaluate_model(Y_test, preds_test, \"Baseline\")\n",
    "\n",
    "# Regresión Lineal\n",
    "model_linear = LinearRegression()\n",
    "model_linear.fit(X_train, Y_train)\n",
    "preds_test = model_linear.predict(X_test)\n",
    "evaluate_model( Y_test, preds_test, \"Lineal\")\n",
    "\n",
    "# Tu código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados han de ser algo así:\n",
    "\n",
    "<center>\n",
    "\n",
    "| Modelo                 | MAE Test  | MSE Test  | R² Test  |\n",
    "|------------------------|-----------|-----------|----------|\n",
    "| *Baseline*             | 5.882     | 52.489    | -0.008   |\n",
    "| *Lineal*               | 1.056     |  2.298    |  0.956   |\n",
    "| *KNN*                  | 0.820     |  1.801    |  0.965   |\n",
    "| *Árboles de Decisión*  | 1.110     |  3.575    |  0.931   |\n",
    "| *SVR*                  | 0.735     |  1.738    |  0.967   |\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.3. Red neuronal**\n",
    "\n",
    "Una vez tenemos los conjuntos y los resultados de los modelos tradicionales ya podemos crear nuestra primera red neuronal desde cero.\n",
    "\n",
    "Los pasos para crear y entrenar una red neuronal son los siguientes:\n",
    "\n",
    "1) Crear la arquitectura del modelo.\n",
    "2) Detallar el optimizador, la función de pérdida y compilar.\n",
    "3) Entrenar y evaluar.\n",
    "\n",
    "#### **2.3.1. Crear arquitectura**\n",
    "\n",
    "Lo primero que tenemos que definir es su arquitectura, es decir, el número de capas completamente conectadas que la forman. \n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <strong>Nota:</strong> Como ya sabes, el tamaño de la capa de entrada y la capa de salida viene determinado por el problema a resolver. En este caso tenemos 1 entrada y una salida.\n",
    "</div>\n",
    "\n",
    "La red más sencilla en este caso será la siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "\n",
    "# Fijar las semillas de las librerías para que los resultados se repitan.\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# Definir las capas del modelo\n",
    "model = Sequential()\n",
    "model.add(Input(shape =(1,)))\n",
    "model.add(Dense(1, name=\"output_layer\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El código anterior simplemente crea un modelo `Sequential()`, es decir, un modelo donde las capas se añaden una después de otra. \n",
    "\n",
    "A continuación vamos introduciendo las siguientes capas en el mismo:\n",
    "\n",
    "* `Input()`: Capa de entrada. No es una capa como tal, simplemente sirve para que el modelo conozca el tamaño de las entradas.\n",
    "* `Dense()`: Capa totalmente conectada ( $y=Wx+b$ ). Le indicamos el tamaño como parámetro obligatorio, el `name` es opcional.\n",
    "\n",
    "Para ver la arquitectura final de nuestro modelo podemos ejecutar el método `summary()` que además nos dá información sobre los parámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cabe destacar que, como mencionamos previamente, al no ser una capa como tal, `Input()` ni siquiera aparece. \n",
    "\n",
    "Otro dato relevante es el número de parámetros o pesos del modelo, es decir, cuantos $W$ y $b$ tiene que aprender durante el entrenamiento para transformar correctamente la entrada en la salida. \n",
    "\n",
    "En este caso son solo 2, un $w$ y un $b$.\n",
    "\n",
    "#### **2.3.2. Compilar el modelo**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La compilación de un modelo en Keras es un paso esencial antes de entrenarlo. Sirve para configurar el proceso de aprendizaje, especificando cómo se optimizará el modelo y cómo se evaluará su rendimiento. En esencia, define los siguientes elementos clave:\n",
    "\n",
    "*   **Optimizador (Optimizer):** Define el algoritmo que se utilizará para ajustar los pesos del modelo durante el entrenamiento, buscando minimizar la función de pérdida. Ejemplos comunes son `Adam`, `SGD`, `RMSprop`, entre otros. Cada optimizador tiene sus propios hiperparámetros (como el learning rate) que pueden ajustarse.\n",
    "\n",
    "*   **Función de Pérdida (Loss Function):**  Mide la diferencia entre las predicciones del modelo y los valores reales (etiquetas). El objetivo del entrenamiento es **minimizar esta pérdida**. La elección de la función de pérdida depende del tipo de problema (clasificación, regresión, etc.). Ejemplos: `categorical_crossentropy` (para clasificación multiclase), `binary_crossentropy` (para clasificación binaria o multietiqueta), `mean_squared_error` o `mean_absolute_error` (para regresión).\n",
    "\n",
    "A continuación compilamos el modelo indicando el optimizador `Adam` con un `learning_rate=0.05` y una función de pérdida de regresión (`mean_absolute_error`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "learning_rate = 0.001\n",
    "optim = Adam(learning_rate=learning_rate)\n",
    "model.compile(loss='mean_absolute_error', optimizer=optim )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2.3.3. Entrenar y evaluar**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente paso es el entrenamiento y evaluación del modelo. En `keras` el entrenamiento se realiza a través del método [`.fit()`](https://keras.io/api/models/model_training_apis/), al igual que sucedía en `scikit-learn`.\n",
    "\n",
    "Este método también recibe los datos de entrenamiento ($X$ e $Y$) y ajusta los pesos del modelo (las $W$ y los $b$) iterativamente para minimizar la función de pérdida (loss function).\n",
    "\n",
    "En detalle, este método realiza los siguientes pasos:\n",
    "\n",
    "1) **Creación de batches:** Divide todo el conjunto de entrenamiento en batches (bloques de ejemplos) y obtiene la predicción del modelo para cada batch. Las redes neuronales están pensadas para trabajar con conjuntos de datos muy grandes y muchas veces no es posible entrenar con todo el conjunto a la vez como hacíamos en los métodos de aprendizaje automático anteriores.\n",
    "2) **Calcula la loss:** Compara las predicciones del modelo $\\hat{Y}$ con las etiquetas reales $Y$ y calcula la pérdida indicada a la hora de compilar, $MAE$ en este caso.\n",
    "3) **Calcula los gradientes:** Utiliza el algoritmo de backpropagation para calcular los gradientes de la función de pérdida con respecto a los pesos del modelo.  Los gradientes indican la dirección y magnitud del cambio necesario en los pesos para reducir la loss.\n",
    "\n",
    "<center>\n",
    "    <div style=\"border-radius:5px; padding:10px; background:white; max-width:900px\">\n",
    "        <img src=\"https://i.imgur.com/1tscXrJ.png\">   \n",
    "    </div>\n",
    "</center>\n",
    "\n",
    "4) **Actualiza los pesos:**  Ajusta los pesos del modelo utilizando el optimizador basado en los gradientes calculados.  El optimizador determina cómo se actualizan los pesos para minimizar la pérdida de manera eficiente.\n",
    "5) **Repite el proceso:** Repite los pasos anteriores para cada uno de los batchs de entrenamiento. Cuando se acaban los batches, se puede volver a repetir todo el proceso durante un número determinado de épocas (epochs).\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <strong>Nota:</strong> Una época (epoch) representa una pasada completa por todo el conjunto de datos de entrenamiento.\n",
    "</div>\n",
    "\n",
    "A continuación entrenamos el modelo con los datos de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo. el parámetro verbose del método train permite configurar la cantidad de información que se muestra por consola durante el entrenamiento\n",
    "history = model.fit(X_train, Y_train, validation_split=0.2, batch_size=64, epochs=200, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <strong>Nota:</strong> Cada vez que ejecutes el bloque anterior <strong>se continuará</strong> con el entrenamiento en el punto que había finalizado. Para entrenar el modelo desde cero tendrías que volver a crearlo y compilarlo.\n",
    "</div>\n",
    "\n",
    "Como puedes ver, hay un argumento en el método `fit` del que no hemos hablado: `validation_split`. \n",
    "\n",
    "Este argumento reserva una fracción de los datos de entrenamiento para usarla como conjunto de validación; es decir, separa un $20\\%$ de los ejemplos del conjunto de entrenamiento (en este caso, dado que `validation_split=0.2`).\n",
    "\n",
    "Por tanto ahora nuestro conjunto de datos está dividido en tres bloques distintos: Train, Validation y Test. Este enfoque también se conoce como **metavalidación**.\n",
    "\n",
    "##### **Metavalidación**\n",
    "\n",
    "Hasta ahora, para validar nuestro modelo habíamos empleado la **validación simple** o hold-out, es decir, habíamos dividido en: Train y Test.\n",
    "\n",
    "Este enfoque es muy válido para casos donde los modelos que queremos evaluar no tienen **hiperparámetros**, como la regresión lineal.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <strong>Nota:</strong> El conjunto de validación sirve para ajustar los hiperparámetros del modelo. <hr>\n",
    "    Recuerda que un hiperparámetro es todo aquel valor que nosotros podemos indicar a la hora de crear un modelo, por ejemplo la K del KNN.\n",
    "</div>\n",
    "\n",
    "Las redes neuronales poseen múltiples hiperparámetros que ajustar como `learning rate`, `batch size`, `epochs`, `número de capas`, `número de neuronas`, etc. Por eso es necesario este conjunto de validación.\n",
    "\n",
    "Por tanto ahora, el proceso de entrenamiento cambia ligeramente: A partir de los datos de Train, el modelo calcula la loss y actualiza los pesos según corresponda, a continuación *calcula la pérdida en el conjunto de validación* **pero no actualiza los pesos con estos datos**.\n",
    "\n",
    "Esto permite:\n",
    "\n",
    "* **Monitorizar el sobreajuste (overfitting):**  Si el rendimiento en el conjunto de entrenamiento mejora continuamente, pero el rendimiento en el conjunto de validación se estanca o empeora, esto indica que el modelo está empezando a sobreajustarse a los datos de entrenamiento y perdiendo su capacidad de generalizar a datos nuevos.\n",
    "* **Ajustar hiperparámetros:**  Ajustaremos los valores de los hiperparámetros buscando seleccionar la configuración que produce el mejor rendimiento en los datos de validación.\n",
    "\n",
    "<hr>\n",
    "\n",
    "##### **¿Por qué no utilizamos directamente Test para ajustar los hiperparámetros?**\n",
    "\n",
    "Imagina que quieres preparar el bizcocho perfecto para llevarlo a un concurso de repostería.\n",
    "\n",
    "* **Conjunto de entrenamiento (train)** Son todas las pruebas que haces en casa con distintas recetas, temperaturas y tiempos. Aquí pruebas muchas combinaciones para aprender cómo afecta cada cambio.\n",
    "\n",
    "* **Conjunto de validación (val)** Cada vez que haces un bizcocho en casa, dejas que lo prueben tus amigos o familia. Ellos te dicen si está muy seco, muy dulce, si la textura es buena... Con ese feedback ajustas la receta: ¿más azúcar? ¿menos tiempo de horno? Ese es el proceso de ajustar hiperparámetros.\n",
    "\n",
    "* **Conjunto de prueba (test)** Es el jurado del concurso. Nunca les diste a probar ninguno de tus bizcochos. Ellos evaluarán si, más allá de tus ajustes, tu receta funciona de verdad.\n",
    "\n",
    "**¿Dónde estaría la trampa?**\n",
    "\n",
    "Si, antes del concurso, tú haces que el jurado pruebe varios bizcochos y te diga qué cambiar, cuando vayas al concurso, ya sabrás lo que les gusta. \n",
    "No estarás probando si tu receta es buena en general, sino que habrás hecho un bizcocho a medida para ellos.\n",
    "\n",
    "<hr>\n",
    "\n",
    "\n",
    "En resumen: \n",
    "* **Train:** Conjunto de datos empleado para entrenar el modelo, ajustando sus pesos con el fin de minimizar la función de pérdida. \n",
    "* **Validation:** Conjunto de datos utilizado para monitorizar el sobreajuste y optimizar los hiperparámetros del modelo, **pero no los pesos**. \n",
    "* **Test:** Conjunto de datos empleado para evaluar el rendimiento final del modelo entrenado con los hiperparámetros óptimos y datos no utilizados previamente (ni para entrenar ni para ajustar hiperparámetros).\n",
    "\n",
    "El método `fit()` retorna un objeto que almacena todo el historial del entrenamiento del modelo a lo largo de las epochs. En este caso almacenamos el resultado en `history`.\n",
    "\n",
    "Vamos a crear una función para visualizar la evolución de las losses de entrenamiento y validación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "def plot_loss_history(history):\n",
    "    # Extraer datos del historial\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history.get('val_loss', []) # Usamos lista vacía por defecto\n",
    "    epochs = range(1, len(loss) + 1)\n",
    "    # Construir el DataFrame\n",
    "    data = pd.DataFrame({ 'Epoch': epochs, 'Loss': loss, 'Type': 'Train' })\n",
    "    # Si existe validación, concatenamos esos datos\n",
    "    if val_loss:\n",
    "        val_df = pd.DataFrame({ 'Epoch': epochs, 'Loss': val_loss, 'Type': 'Validation' })\n",
    "        data = pd.concat([data, val_df], ignore_index=True)\n",
    "    # Crear el gráfico\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.lineplot(data=data, x=\"Epoch\", y=\"Loss\", hue=\"Type\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Evolución de la Pérdida durante el Entrenamiento\")\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    # Solo mostrar leyenda si hay más de un tipo de dato\n",
    "    if val_loss: plt.legend(title=\"Conjunto\")\n",
    "    else: plt.legend().remove() # Evita leyendas vacías o innecesarias\n",
    "    plt.show()\n",
    "\n",
    "# Llamada a la función (después de entrenar el modelo)\n",
    "plot_loss_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Ejercicio:</b> Por simplicidad vamos juntar la creación y complilación de la red dentro de una función. Completa el siguiente código y vuelve a entrenar red desde cero. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def red_neuronal_uno(learning_rate):\n",
    "    # Creamos y compilamos el modelo\n",
    "    \n",
    "    # Tu código aquí\n",
    "\n",
    "    return model\n",
    "\n",
    "# Creamos la red desde cero\n",
    "model_1 = red_neuronal_uno(learning_rate = 0.001)\n",
    "\n",
    "# Entrenamos\n",
    "# Tu código aquí\n",
    "\n",
    "# Visualizar entrenamiento\n",
    "# Tu código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Ajuste de hiperparámetros**\n",
    "\n",
    "Una vez tenemos todo junto en un único bloque de código, podemos pasar a la parte de ajuste de hiperparámetros. \n",
    "\n",
    "Hay muchas cosas que podemos ajustar ( `batch size`, `epochs`, `learning rate`, ...) pero vamos a centrarnos en el `learning rate`.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Ejercicio:</b> Anota los resultados de la última epoch del modelo anterior en la siguiente tabla y realiza los experimentos necesarios para completar el resto de filas.\n",
    "</div>\n",
    "\n",
    "\n",
    "<center>\n",
    "\n",
    "| Modelo                    | MAE Train  | MAE Val |\n",
    "|---------------------------|------------|---------|\n",
    "| *Red Neuronal (lr=0.001)* |            |         |\n",
    "| *Red Neuronal (lr=0.05)*  |            |         |\n",
    "| *Red Neuronal (lr=0.1)*   |            |         |\n",
    "\n",
    "</center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Ejercicio:</b> Entrena el modelo final con el mejor <code>learning_rate</code> y evalúa en test utilizando el método <code>.predict()</code> y la función <code>evaluate_model()</code> creada previamente.\n",
    "    <hr>\n",
    "    Añade los resultados a la tabla.\n",
    "</div>\n",
    "\n",
    "<center>\n",
    "\n",
    "| Modelo                 | MAE Test  | MSE Test  | R² Test  |\n",
    "|------------------------|-----------|-----------|----------|\n",
    "| *Baseline*             | 5.882     | 52.489    | -0.008   |\n",
    "| *Lineal*               | 1.056     |  2.298    |  0.956   |\n",
    "| *KNN*                  | 0.820     |  1.801    |  0.965   |\n",
    "| *Árboles de Decisión*  | 1.110     |  3.575    |  0.931   |\n",
    "| *SVR*                  | 0.735     |  1.738    |  0.967   |\n",
    "| *Red Neuronal Lineal*  |           |           |          |\n",
    "\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Añadiendo no linealidad**\n",
    "\n",
    "Realizaremos algunas modificaciones y crearemos un modelo distinto, algo más complejo, para comprobar si podemos mejorar el rendimiento.\n",
    "\n",
    "Como recordarás, no todos los problemas tienen una solución lineal. Una red neuronal básica como la nuestra se limita a realizar combinaciones lineales de números (sumas y multiplicaciones), es decir, transforma la entrada en la salida mediante la fórmula $y=Wx + b$.\n",
    "\n",
    "Para añadir no linealidad, necesitamos introducir **funciones de activación no lineales**. Estas funciones se aplican a la salida de cada capa y permiten que la red aprenda relaciones más complejas entre las entradas y las salidas. Algunas funciones de activación comunes incluyen `ReLU`, `sigmoid` y `tanh`. Al agregar estas funciones, la red puede aproximar funciones no lineales y resolver problemas más desafiantes.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <strong>Nota:</strong> Si queremos que el modelo aprenda relaciones <b>no lineales</b>, necesitamos introducir estas funciones de activación no lineales <b>en capas ocultas, no solo en la de salida</b>.\n",
    "</div>\n",
    "\n",
    "<center>\n",
    "    <div style=\"border-radius:5px; padding:10px; background:white; max-width:900px\">\n",
    "        <img src=\"https://i.imgur.com/e7kd5fs.png\">   \n",
    "    </div>\n",
    "</center>\n",
    "\n",
    "Nuestro actual modelo solo tiene una capa, la de salida. Si pusiesemos cualquiera de estas funciones en esta capa, **además de no conseguir no linealidad**, estaríamos restringiendo significativamente el rango de valores que el modelo puede predecir. \n",
    "\n",
    "Por ejemplo, si solo añadimos una función `sigmoide` en la capa final, tendremos un modelo lineal cuya salida **siempre** se limitará al rango entre 0 y 1. Esto no es lo ideal para nuestro problema de regresión. \n",
    "\n",
    "Para conseguir no linealidad y evitar este inconveniente permitiendo que el modelo prediga en un rango de valores entre $(-\\infty , \\infty)$, añadiremos una capa oculta (o intermedia) y aplicaremos la activación en esta capa. De esta manera, la capa final puede generar salidas sin las restricciones impuestas por la función de activación, al tiempo que conseguimos la no linealidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Ejercicio:</b> Crea, dentro de la función proporcionada, una nueva red neuronal, pero este vez con dos capas siendo la oculta de <b>tamaño 10</b> y con una función de activación <code>tanh</code> para añadir no linealidad. \n",
    "    <br>\n",
    "    Consulta la documentación de la capa <a href=\"https://keras.io/api/layers/core_layers/dense/\"><code>Dense()</code></a>.\n",
    "    <hr>\n",
    "    Busca el mejor <code>learning_rate</code> y evalúa en test con la mejor versión. Rellena ambas tablas.\n",
    "</div>\n",
    "\n",
    "\n",
    "<center>\n",
    "\n",
    "| Modelo                    | MAE Train  | MAE Val |\n",
    "|---------------------------|------------|---------|\n",
    "| *Red Neuronal (lr=0.001)* |            |         |\n",
    "| *Red Neuronal (lr=0.05)*  |            |         |\n",
    "| *Red Neuronal (lr=0.1)*   |            |         |\n",
    "\n",
    "\n",
    "<center>\n",
    "<br> \n",
    "<center>\n",
    "\n",
    "| Modelo                   | MAE Test  | MSE Test  | R² Test  |\n",
    "|--------------------------|-----------|-----------|----------|\n",
    "| *Baseline*               | 5.882     | 52.489    | -0.008   |\n",
    "| *Lineal*                 | 1.056     |  2.298    |  0.956   |\n",
    "| *KNN*                    | 0.820     |  1.801    |  0.965   |\n",
    "| *Árboles de Decisión*    | 1.110     |  3.575    |  0.931   |\n",
    "| *SVR*                    | 0.735     |  1.738    |  0.967   |\n",
    "| *Red Neuronal Lineal*    |           |           |          |\n",
    "| *Red Neuronal No Lineal* |           |           |          |\n",
    "\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def red_neuronal_dos(learning_rate):\n",
    "    # Creamos y compilamos el modelo\n",
    "    \n",
    "    # Tu código aquí\n",
    "\n",
    "    return model\n",
    "\n",
    "# Creamos la red desde cero\n",
    "model_2 = red_neuronal_dos(learning_rate = 0.001)\n",
    "\n",
    "# Tu código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Ejercicio:</b> ¿Con qué modelo te quedarías?.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tu respuesta aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.4. Múltiples entradas**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Ejercicio:</b> Crea un par de redes capaces de predecir <i>LapTime</i> a parir de <i>SpeedI1</i>, <i>SpeedI2</i>, <i>SpeedFL</i>, <i>SpeedST</i> y <i>TyreLife</i>. Ajusta los hiperparámetros de cada modelo.\n",
    "</div>\n",
    "\n",
    "<center>\n",
    "\n",
    "| Modelo                   | MAE Test  | MSE Test  | R² Test  |\n",
    "|--------------------------|-----------|-----------|----------|\n",
    "| *Baseline*               | 5.858     | 54.094    | -0.008   |\n",
    "| *Lineal*                 | 0.932     | 1.678     | 0.969    |\n",
    "| *KNN*                    | 0.785     | 1.743     | 0.968    |\n",
    "| *Árboles de Decisión*    | 0.899     | 1.841     | 0.966    |\n",
    "| *SVR*                    | 0.938     | 2.724     | 0.949    |\n",
    "| *Red Neuronal 1*         |           |           |          |\n",
    "| *Red Neuronal 2*         |           |           |          |\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lap_time = data[[\"LapTime\", \"SpeedI1\", \"SpeedI2\", \"SpeedFL\", \"SpeedST\", \"TyreLife\"]].copy()\n",
    "data_lap_time = data_lap_time.dropna()\n",
    "data_lap_time[\"LapTime\"] = data_lap_time[\"LapTime\"].dt.total_seconds()\n",
    "\n",
    "X = data_lap_time[[\"SpeedI1\", \"SpeedI2\", \"SpeedFL\", \"SpeedST\", \"TyreLife\"]]\n",
    "Y = data_lap_time[\"LapTime\"]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=seed, test_size=.2)\n",
    "\n",
    "standardizer = StandardScaler()\n",
    "X_train = standardizer.fit_transform(X_train)\n",
    "X_test = standardizer.transform(X_test)\n",
    "\n",
    "# Baseline media\n",
    "baseline_media = DummyRegressor(strategy=\"mean\")\n",
    "baseline_media.fit(X_train, Y_train)\n",
    "preds_test = baseline_media.predict(X_test)\n",
    "evaluate_model(Y_test, preds_test, \"Baseline\")\n",
    "\n",
    "# Regresión Lineal\n",
    "model_linear = LinearRegression()\n",
    "model_linear.fit(X_train, Y_train)\n",
    "preds_test = model_linear.predict(X_test)\n",
    "evaluate_model( Y_test, preds_test, \"Lineal\")\n",
    "\n",
    "# KNN\n",
    "model_knn = KNeighborsRegressor()\n",
    "model_knn.fit(X_train, Y_train)\n",
    "preds_test = model_knn.predict(X_test)\n",
    "evaluate_model(Y_test, preds_test, \"KNN\")\n",
    "\n",
    "# Árboles de Decisión\n",
    "model_tree = DecisionTreeRegressor()\n",
    "model_tree.fit(X_train, Y_train)\n",
    "preds_test = model_tree.predict(X_test)\n",
    "evaluate_model(Y_test, preds_test, \"Árboles de Decisión\")\n",
    "\n",
    "# SVR\n",
    "model_svr = SVR()\n",
    "model_svr.fit(X_train, Y_train)\n",
    "preds_test = model_svr.predict(X_test)\n",
    "evaluate_model(Y_test, preds_test, \"SVR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu código aquí"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SSII",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
