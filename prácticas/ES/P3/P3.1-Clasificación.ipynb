{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Práctica 3.1: Aprendizaje Automático (Clasificación)**\n",
    "\n",
    "<hr>\n",
    "\n",
    "## **1. Introducción**\n",
    "Una vez hemos analizado, limpiado y visualizado nuestro conjunto, ya podemos pasar a la fase de aprendizaje. Antes comenzar es necesario identificar a que tipo de problema nos enfrentamos para poder seleccionar los métodos o modelos más adecuados.\n",
    "\n",
    "En el siguiente diagrama se pueden ver los tipos de problemas más comunes dentro del campo del aprendizaje automático:\n",
    "\n",
    "<center><img src=\"https://i.imgur.com/CN1RVmy.png\" alt=\"diagram\" width=\"1000\"/></center>\n",
    "\n",
    "Como ya sabes, los problemas que requieren de **aprendizaje automático** para ser resueltos son aquellos donde desconocemos la *fórmula* que nos permite transformar la entrada en la salida. Dentro de estos hay dos tipos principalmente, **supervisados** y **no supervisados**.\n",
    "\n",
    "En esta asignatura nos centraremos en los problemas de aprendizaje supervisado, que son aquellos donde buscamos predecir, o bien una o varias clases (**clasificación**) o bien uno o varios valores numéricos (**regresión**). \n",
    "\n",
    "Recuerda que para poder resolver problemas de aprendizaje supervisado siempre vamos a necesitar **datos etiquetados**, es decir, datos donde ya conocemos, para una entrada dada, la salida esperada o etiqueta correcta. Estos datos serán los que utilice el modelo para intentar aprender esa *fórmula desconocida* durante el entrenamiento.\n",
    "\n",
    "\n",
    "Vamos a comenzar por los **problemas de clasificación**, sus particularidades, métricas, técnicas de evaluación y cómo se utilizan para realizar predicciones.\n",
    "\n",
    "### **Objetivo**\n",
    "En esta práctica aprenderás a resolver problemas de clasificación utilizando diferentes modelos así como a evaluar su rendimiento. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## **2. Definición del problema**\n",
    "\n",
    "Para comenzar vamos a intentar crear un modelo capaz de resolver un problema de **clasificación binaria**. \n",
    "\n",
    "En este caso se nos pide **crear un modelo que, dado el tiempo (en segundos) de los 3 sectores de un piloto de *Aston Martin*, se prediga si ese tiempo lo realizó *Alonso* o no (*Stroll*)**.\n",
    "\n",
    "Vamos a cargar de nuevo nuestros datos y a generar el conjunto necesario para resolver el problema.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_pickle(\"https://raw.githubusercontent.com/AIC-Uniovi/Sistemas-Inteligentes/refs/heads/main/datasets/f1_23_monaco.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Ejercicio:</b> Crea la variable <code>data_aston</code> con un DataFrame que contenga únicamente los datos de ese equipo y las columnas \"Sector1Time\", \"Sector2Time\", \"Sector3Time\" y \"Driver\"</a>. Transforma las columnas de los sectores de timedelta a segundos con <code>.dt.total_seconds()</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a modificar el conjunto para transformarlo en un problema de clasificación binaria. Como recordarás, en ese tipo de problemas el modelo predice **un único valor** que indica la probabilidad entre cero ($0\\%$) y uno ($100\\%$) de que la entrada dada sea o no de la **clase positiva**.\n",
    "\n",
    "En nuestro caso la **clase positiva** será *\"Alonso\"*, por tanto, si el modelo predice un $1$ nos estará diciendo que los tiempos de los 3 sectores dados en la entrada son de Alonso con un $100\\%$ de probabilidad. \n",
    "\n",
    "Si la predicción del modelo es $0$, o menor de $0.5$, nos estará diciendo que la vuelta no es de Alonso y por tanto de Stroll."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Ejercicio:</b> Crea la columna <code>Class</code> dentro del DataFrame <code>data_aston</code> para que valga cero siempre que el piloto no sea Alonso y 1 en el caso contrario. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## **3. Baseline**\n",
    "\n",
    "Una vez disponemos de un conjunto de datos etiquetados, donde cada entrada (Sector1Time, Sector2Time y Sector3Time) está asociada a una salida esperada (Class), podemos proceder a crear un modelo para resolver el problema de clasificación binaria\n",
    "\n",
    "Como se ha explicado en clase de teoría, existen modelos sencillos que pueden ofrecer muy buen rendimiento sin necesidad de recurrir a soluciones más complejas. \n",
    "Estos modelos se denominan *baselines* y nos sirven para tener una referencia o un límite inferior. Si un baseline tiene mejor rendimiento que un modelo mucho más complejo, algo está funcionando mal. \n",
    "\n",
    "En problemas de clasificación destacan principalmente tres:\n",
    "\n",
    "* **Aleatorio:** Predice aleatoriamente un 0 o un 1 sin tener en cuenta las variables de entrada.\n",
    "* **Zero-R:** Predice la clase mayoritaria, es decir, analiza la columna \"Class\" del conjunto de datos y, si la clase que más aparece es 1, siempre predice, ante cualquier entrada, un 1. Como ves, tampoco utiliza para nada las variables de la entrada.\n",
    "* **One-R:** Este modelo selecciona **una** variable de la entrada, aquella que por sí sola ofrezca la mejor clasificación posible. Pensado para variables de entrada de tipo categórico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <strong>NOTA:</strong> Utilizaremos <i>Aleatorio</i> y <i>Zero-R</i> como baselines para nuestro problema. <i>One-R</i> no es posible, nuestras variables de entrada son numéricas.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Baseline aleatorio**\n",
    "Vamos a crear un modelo que genere predicciones aleatorias (0 o 1) independientemente de las variables de entrada. \n",
    "\n",
    "La implementación es muy sencilla, simplemente hay que generar una lista aleatoria de ceros y unos. A continuación contaremos cuantas veces ha acertado el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Fijamos una semilla para que siempre se generen los mismos valores aleatorios\n",
    "seed = 2533\n",
    "random.seed(seed)\n",
    "# Creamos una lista de tantos valores (0 o 1) como filas tiene nuestro conjunto\n",
    "random_values = [random.choice([0, 1]) for _ in range(len(data_aston))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Ejercicio:</b> ¿Cuántas veces ha acertado el modelo (en porcentaje)? Para obtenerlo tendrás que contar cuantas veces el modelo aleatorio dijo un 1 y realmente era un 1 y cuantas dijo un 0 y realmente era un 0.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    Ese valor que acabas de obtener, es una de las <strong>métricas</strong> más populares de <strong>clasificación</strong> y se denomina <strong>accuracy</strong>. Simplemente cuenta el número de aciertos del modelo sobre el máximo posible.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Zero-R**\n",
    "A continuación obtendremos el resultado del baseline *Zero-R*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Ejercicio:</b> ¿Cuál es la clase mayoritaria del conjunto de datos? Teniendo esto en cuenta, ¿Cuál será la <strong>accuracy</strong> del <i>Zero-R</i>?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Evaluación del modelo**\n",
    "\n",
    "En este punto **ya tenemos dos modelos** capaces de resolver nuestro problema de clasificación binaria, el **Aleatorio** y el **Zero-R**. Además, ya sabemos que estos modelos tienen una accuracy en **resustitución** de aproximadamente un $35\\%$ y $60\\%$.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <strong>Resustitución:</strong> Proceso por el que un modelo <u>se entrena y evalúa utilizando el mismo conjunto</u>. Este procedimiento puede ofrecer una estimación inicial del rendimiento del modelo, aunque <strong>no refleja su capacidad de generalización</strong>.\n",
    "</div>\n",
    "\n",
    "Es importante recordar que cuando creamos un modelo de aprendizaje automático buscamos que este no solo funcione bien con los datos conocidos, **sino que sea capaz de realizar predicciones sobre datos nuevos y no vistos**.\n",
    "\n",
    "Con esto en mente, podemos notar que la evaluación que acabamos de realizar sobre nuestros modelos no es del todo adecuada. Lo que hemos medido es qué tan bien predicen los ejemplos que ya conocen, pero no su capacidad para hacer predicciones sobre datos futuros, que es lo realmente relevante.\n",
    "\n",
    "\n",
    "### **Estrategias**\n",
    "Para solucionar este problema, en lugar de evaluar el modelo sobre los mismos datos con los que ha aprendido, vamos a evaluarlo sobre una parte del conjunto que habremos separado previamente (conjunto de prueba o test).\n",
    "\n",
    "Ese subconjunto se suele crear apartando del conjunto original un porcentaje ($20\\%$ típicamente) de ejemplos seleccionados aleatoriamente y se utilizará únicamente para evaluar el rendimiento del modelo, no para entrenar. Haciendo esto, *\"simularemos\"* casos futuros no vistos y, si el modelo tiene buena accuracy sobre este conjunto, sabremos que es bueno realmente.\n",
    "\n",
    "Esta estrategia se denomina **Validación simple**, pero existen muchas otras: \n",
    "\n",
    "- **Validación cruzada**: Consiste en dividir los datos en varios subconjuntos (*folds*), entrenar el modelo en algunos de ellos y evaluarlo en los restantes, repitiendo el proceso varias veces. Esto ayuda a obtener una estimación más estable del desempeño del modelo.  \n",
    "- **Validación con conjunto de validación**: Se emplea un tercer subconjunto, distinto del de test, para ajustar los hiperparámetros del modelo y evitar el sobreajuste. Muy típico cuando se utilizan redes neuronales.  \n",
    "\n",
    "Para obtener una evaluación más realista del rendimiento de nuestros modelos, vamos a aplicar **validación simple** y obtener de nuevo su accuracy, pero esta vez sobre el conjunto de test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Ejercicio:</b> Separa el conjunto <code>data_aston</code> en entrenamiento y test (80% y 20%) y almacena los subconjuntos en <code>data_aston_train</code> y <code>data_aston_test</code>. Utiliza para ello la función <code><a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\">train_test_split()</a></code> de la librería <i>scikit-learn</i> que tendrás que instalar en tu environment conda previamente. \n",
    "    <hr>\n",
    "    <strong>Fija la semilla de la función para que siempre realize la misma división (random_state=2533)</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Ejercicio:</b> ¿Cuál es ahora la accuracy del Aleatorio sobre el conjunto de test?. Recuerda volver a fijar la semilla.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Ejercicio:</b> ¿Cuál es ahora la accuracy del Zero-R sobre el conjunto de test?.\n",
    "    <hr>\n",
    "    Recuerda que has de recalcular la clase mayoritaria utilizando el nuevo conjunto de entrenamiento (es lo único que debería conocer tu modelo) y con ella evaluar en test.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como acabas de ver, los modelos han obtenido valores muy cercanos al $50\\%$ de accuracy en test, lo que deja mucho que desear.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <strong>Nota:</strong> El peor modelo de clasificación binaria posible tendrá un 50% de accuracy, no un 0%. Uno con el 0% estaría acertando todo, pero habría que invertir sus predicciones. \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## **5. Scikit-Learn**\n",
    "\n",
    "La librería `Scikit-learn` utilizada previamente, posee una gran cantidad de modelos y herramientas que nos serán de utilidad para resolver problemas de aprendizaje automático.\n",
    "\n",
    "Por ejemplo, los baselines que acabamos de implementar ya vienen incorporados dentro de la clase `DummyClassifier()`.\n",
    "\n",
    "Esta clase posee el parámetro `strategy` que nos permite seleccionar el baseline deseado y puede tomar, entre otros, los siguientes valores:\n",
    "- **uniform**: Equivalente a nuestro *Aleatorio*. \n",
    "- **most_frequent**: Equivalente a *Zero-R*. \n",
    "\n",
    "En el siguiente código vemos cómo podemos utilizar esta clase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# Creamos los modelos\n",
    "baseline_aleatorio = DummyClassifier(strategy=\"uniform\", random_state=seed)\n",
    "baseline_zeror = DummyClassifier(strategy=\"most_frequent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez creados los modelos, el siguiente paso es entrenarlos, y para ello hay que proporcionales, mediante el método `fit()`. los datos de entrenamiento, en concreto la $X$ y la $Y$.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <strong>Nota:</strong> En aprendizaje supervisado, denominamos X a las variables independientes o <i>entradas</i> e Y a las variables dependientes o <i>salidas</i>. \n",
    "</div>\n",
    "\n",
    "Como ya sabes, el objetivo del modelo es *aprender* la relación entre $X$ e $Y$ para poder predecir la $Y$ a partir de nuevas $X$ desconocidas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Ejercicio:</b> Crea las variables X e Y para entrenar los modelos. Recuerda que hemos dividido el conjunto en dos partes.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu código aquí\n",
    "\n",
    "# Entrenamos\n",
    "baseline_aleatorio.fit(X, Y)\n",
    "baseline_zeror.fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez tenemos el modelo entrenado, ya podemos realizar predicciones para evaluar su desempeño con datos no vistos durante el entrenamiento. En `scikit-learn` esto se hace mediante la función `predict()`.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <strong>Nota:</strong> Esta función solo recibe las X (no las Y) y retorna las Y predichas. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = data_aston_test[[\"Sector1Time\",\"Sector2Time\",\"Sector3Time\"]]\n",
    "Y_test = data_aston_test[[\"Class\"]]\n",
    "\n",
    "# Predecir\n",
    "pred_aleatorio = baseline_aleatorio.predict(X_test)\n",
    "pred_zeror = baseline_zeror.predict(X_test)\n",
    "\n",
    "# Imprimir resultados\n",
    "print(pred_aleatorio)\n",
    "print(pred_zeror)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra ventaja de esta librería es que trae implementadas multitud de métricas dentro del paquete `metrics`, por lo que podremos obtener la accuracy de manera muy sencilla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.accuracy_score(Y_test, pred_aleatorio))\n",
    "print(metrics.accuracy_score(Y_test, pred_zeror))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Ejercicio:</b> Obtén las matrices de confusión de los modelos utilizando <a href=\"https://scikit-learn.org/stable/api/sklearn.metrics.html\">el método implementado en la librería</a>. Obtén también la <i>Precission, Recall y F1</i> con los métodos o las fórmulas.\n",
    "</div>\n",
    "\n",
    "<div style=\"width:800px;background:white;padding:10px\">\n",
    "    <img src=\"https://i.imgur.com/7WwY9bZ.jpeg\" style=\"margin-bottom:10px\"> </img>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## **6. Otros modelos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como ya has visto en clase de teoría, además de los baselines que acabamos utilizar, existen muchos otros modelos diferentes para resolver problemas de clasificación. Algunos de ellos pueden ser: \n",
    "\n",
    "* **Regresión logistica:** Modelo \"lineal\" que utiliza una función logística (sigmoide) para predecir la probabilidad de pertenencia a una clase.\n",
    "* **K-Nearest Neighbors:** Clasificador que asigna una instancia a la clase más frecuente entre sus k vecinos más cercanos.\n",
    "* **Arboles de decisión:** Modelo de clasificación que crea un árbol que permite tomar decisiones basadas en las características de los datos (entradas).\n",
    "* **SVM:** Algoritmo de clasificación que busca el hiperplano óptimo que maximiza el margen entre las clases.\n",
    "* **Redes Neuronales:** Las veremos en detalle en los próximos temas.\n",
    "\n",
    "Al igual que sucedía con los baselines, `scikit-learn` nos proporciona muchos la mayoría ya implementados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <strong>Nota:</strong> Antes de utilizar otros modelos, es necesario llevar a cabo una fase del <u>preprocesamiento de datos</u> que teníamos pendiente: La <strong>normalización o la estandarización</strong> de datos. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como recordarás, esta fase se encarga de que todas las <u>entradas</u> a nuestro modelo (tiempos de sectores en nuestro caso) se muevan en el mismo rango (normalización) o tengan la misma media y desviación (estandarización) para facilitar el aprendizaje.\n",
    "\n",
    "Hasta ahora no lo hemos realizado por que los baselines anteriores no utilizaban para nada la información de entrada, uno predecía de forma aleatoria y el otro predecía la clase más frecuente.\n",
    "\n",
    "Realizaremos, en este caso una estandarización (una normalización también sería válida). Vamos a verificar la media y desviación de las entradas previamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Media y desviación de las entradas de nuestro modelo\n",
    "X.describe().loc[[\"mean\", \"std\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Ejercicio:</b> Utiliza el <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\"><code>StandardScaler()</code></a> de <i>sklearn</i> para estandarizar las X de train y de test. Almacena los nuevos datos en <code>X_std</code> y <code>X_test_std</code>. Recuerda que los datos de test son desconocidos para nosotros, por lo que no pueden influir a la hora de calcular la media y las desviación.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "standardizer = StandardScaler()\n",
    "# Tu código aquí\n",
    "\n",
    "# Verifica con: \n",
    "print(X_std.mean(axis=0))\n",
    "print(X_std.std(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6.1. Regresión Logística**\n",
    "\n",
    "Ya tenemos todo listo para entrenar y evaluar nuevos modelos <u>buscando mejorar las métricas de los baselines</u>. Comenzaremos por la **Regresión logística**.\n",
    "\n",
    "Para utilizarla simplemente tendremos que crear un objeto de la clase `LogisticRegression()`, entrenarlo con el `fit()` y evaluarlo con `predict()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Creamos, entrenamos y evaluamos el modelo\n",
    "model_log = LogisticRegression()\n",
    "model_log.fit(X_std, Y.squeeze()) # El squeeze elimina dimensiones innecesarias\n",
    "pred_log = model_log.predict(X_test_std)\n",
    "print(metrics.accuracy_score(Y_test, pred_log))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como ves, este modelo obtiene mejores resultados en términos de accuracy, pero no mucho mejores.\n",
    "\n",
    "Podemos visualizar también su **matriz de confusión**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "conf_mat_log = metrics.confusion_matrix(Y_test, pred_log)\n",
    "\n",
    "plt.figure(figsize=(2,2)); # Tamaño del plot\n",
    "sns.heatmap(conf_mat_log, annot=True, cbar=False)\n",
    "plt.ylabel(\"Real (y)\")\n",
    "plt.xlabel(\"Predicción (y_hat)\")\n",
    "plt.title(\"Matriz de confusión\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6.2. K-Nearest Neighbors**\n",
    "\n",
    "El siguiente modelo que podemos probar es el `KNeighborsClassifier()`, que se usa exactamente igual que el resto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Creamos, entrenamos y evaluamos el modelo\n",
    "model_knn = KNeighborsClassifier(n_neighbors=3)\n",
    "model_knn.fit(X_std, Y.squeeze())\n",
    "pred_knn = model_knn.predict(X_test_std)\n",
    "print(metrics.accuracy_score(Y_test, pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados en términos de accuracy con este modelo son muy próximos al $100\\%$, lo que lo hace el mejor de los evaluados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6.3. Árboles de decisión**\n",
    "A continuación analizaremos el rendimiento que tiene un árbol de decisión a la hora de resolver esta tarea. La clase dentro de la librería se denomina `DecisionTreeClassifier()` y presenta numerosos hiperparámetros, siendo uno de los más destacados `max_depth`, que permite establecer la profundidad máxima del árbol y por tanto controlar el **sobreajuste**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Creamos, entrenamos y evaluamos el modelo\n",
    "model_tree = DecisionTreeClassifier(random_state=seed, max_depth=2)\n",
    "model_tree.fit(X_std, Y.squeeze())\n",
    "pred_tree = model_tree.predict(X_test_std)\n",
    "print(metrics.accuracy_score(Y_test, pred_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El rendimiento es similar al modelo anterior, pero este posee la ventaja de permitirnos ver su funcionamiento interno, es decir, el árbol que ha creado. Para ello, tendremos que instalar una nueva librería."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "from IPython.display import Image\n",
    "import pydotplus\n",
    "\n",
    "# Exportamos el árbol resultante a formato DOT\n",
    "dot_data = export_graphviz(decision_tree=model_tree, feature_names=X.columns, class_names=['Stroll', 'Alonso'], filled=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6.4. Support Vector Machines (SVM)**\n",
    "El último modelo que vamos a probar es el SVM y está implementado en la clase `SVC()`. Comenzaremos por un **kernel lineal**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Creamos un SVM con kernel lineal entrenamos y evaluamos\n",
    "model_svm = SVC(kernel='linear')\n",
    "model_svm.fit(X_std, Y.squeeze())\n",
    "pred_svm = model_svm.predict(X_test_std)\n",
    "print(metrics.accuracy_score(Y_test, pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La accuracy no es muy alta, por lo que es posible que las clases no sean **linealmente separables**. \n",
    "\n",
    "Para mejorar el rendimiento probaremos ahora con un **kernel polinómico** de grado 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un SVM con kernel polinómico de grado 2 y término independiente 1. Entrenamos y evaluamos\n",
    "model_svm_p = SVC(kernel='poly', degree=2, coef0=1)\n",
    "model_svm_p.fit(X_std, Y.squeeze())\n",
    "pred_svm_p = model_svm_p.predict(X_test_std)\n",
    "print(metrics.accuracy_score(Y_test, pred_svm_p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como ves, la no linealidad de este modelo permite resolver el problema con una precisión idéntica a los mejores modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Ejercicio:</b> Completa la función <code>train_and_eval()</code> para el resto de modelos incluyendo las dos versiones del SVM. Esta hace uso de la función <code>train_and_eval_model()</code> implementada a continuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval_model(model_name, model, X_std, Y, X_test_std, Y_test):\n",
    "    # Entrenar el modelo\n",
    "    model.fit(X_std, Y.squeeze())\n",
    "    # Predicciones\n",
    "    Y_train_pred = model.predict(X_std)\n",
    "    Y_test_pred = model.predict(X_test_std)\n",
    "    # Calcular métricas para train\n",
    "    tr_accuracy = metrics.accuracy_score(Y, Y_train_pred)\n",
    "    tr_precision = metrics.precision_score(Y, Y_train_pred, zero_division=0)\n",
    "    tr_recall = metrics.recall_score(Y, Y_train_pred)\n",
    "    tr_f1 = metrics.f1_score(Y, Y_train_pred)\n",
    "    \n",
    "    # Calcular métricas para test\n",
    "    tst_accuracy = metrics.accuracy_score(Y_test, Y_test_pred)\n",
    "    tst_precision = metrics.precision_score(Y_test, Y_test_pred, zero_division=0)\n",
    "    tst_recall = metrics.recall_score(Y_test, Y_test_pred)\n",
    "    tst_f1 = metrics.f1_score(Y_test, Y_test_pred)\n",
    "    return (model_name, \n",
    "            tr_accuracy, tr_precision, tr_recall, tr_f1, \n",
    "            tst_accuracy, tst_precision, tst_recall, tst_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval(X_std, Y, X_test_std, Y_test):\n",
    "    # Creamos una lista donde almacenar los resultados de cada modelo\n",
    "    all_results = []\n",
    "    \n",
    "    # Baseline aleatorio\n",
    "    baseline_aleatorio = DummyClassifier(strategy=\"uniform\", random_state=seed)\n",
    "    model_results = train_and_eval_model(\"Aleatorio\", baseline_aleatorio, X_std, Y, X_test_std, Y_test)\n",
    "    all_results.append(model_results)\n",
    "    \n",
    "    # Tu código aquí\n",
    "\n",
    "    # Imprimir el dataframe resultante\n",
    "    multi_index = pd.MultiIndex.from_tuples([ (\"Modelo\", \"Nombre\"), (\"Train\", \"Accuracy\"), (\"Train\", \"Precision\"), (\"Train\", \"Recall\"), (\"Train\", \"F1\"), (\"Test\", \"Accuracy\"), (\"Test\", \"Precision\"), (\"Test\", \"Recall\"), (\"Test\", \"F1\") ])    \n",
    "    all_results = pd.DataFrame(all_results, columns=multi_index)\n",
    "    display(all_results)\n",
    "\n",
    "train_and_eval(X_std, Y, X_test_std, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Ejercicio:</b> ¿Cuál crees que es el mejor modelo? ¿Por qué?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu respuesta aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Ejercicio:</b> Crea un modelo capaz de predecir, a partir de los 3 sectores de un piloto, si el neumático con el que realizó la vuelta es de lluvia (\"INTERMEDIATE\" o \"WET\") o no. Realiza todo el preprocesamiento que creas necesario y prueba todos los modelos de clasificación vistos hasta ahora utilizando la función anterior.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu código aquí"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SSII",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
